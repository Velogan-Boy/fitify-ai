{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 09:43:00.934990: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-23 09:43:00.979026: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-23 09:43:00.979058: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-23 09:43:00.980151: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-23 09:43:00.986098: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-23 09:43:00.986524: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-23 09:43:02.022741: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1713845583.060933   19130 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1713845583.063718   19272 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.2), renderer: Mesa Intel(R) UHD Graphics 620 (KBL GT2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    \"\"\"\n",
    "    Processes and organizes the keypoints detected from the pose estimation model \n",
    "    to be used as inputs for the exercise decoder models\n",
    "    \n",
    "    \"\"\"\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten()\n",
    "\n",
    "    return pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/dell/.local/lib/python3.10/site-packages/cv2/qt/plugins\"\n"
     ]
    }
   ],
   "source": [
    "# model = load_model(\"../models/LSTM.h5\")\n",
    "model = load_model(\"../models/LSTM_Attention_128HUs.h5\")\n",
    "# model = load_model(\"../models/CNN_BLSTM model.h5\")\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture('../dataset/squat/squat_11.mp4')\n",
    "# cap = cv2.VideoCapture('../dataset/hammer curl/hammer curl_11.mp4')\n",
    "# cap = cv2.VideoCapture('../dataset/barbell biceps curl/barbell biceps curl_11.mp4')\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "\n",
    "sequence = []\n",
    "actions = np.array(['barbell biceps curl','bench press','chest fly machine','deadlift','decline bench press',\n",
    "                  'hammer curl','hip thrust','incline bench press','lat pulldown','lateral raise',\n",
    "                  'leg extension','leg raises','plank','pull Up','push-up','romanian deadlift',\n",
    "                  'russian twist','shoulder press','squat','t bar row','tricep Pushdown','tricep dips'])\n",
    "current_action = ''\n",
    "\n",
    "prev_frame_time = 0\n",
    "new_frame_time = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "      ret, frame = cap.read()\n",
    "    \n",
    "      if not ret: \n",
    "            break\n",
    "      \n",
    "      rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "      results = pose.process(rgb_frame)\n",
    "    \n",
    "      if results.pose_landmarks:\n",
    "            landmarks = extract_keypoints(results)\n",
    "            mp.solutions.drawing_utils.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "      else: \n",
    "            continue \n",
    "      \n",
    "      sequence.append(landmarks)\n",
    "      \n",
    "      if len(sequence) == SEQUENCE_LENGTH:\n",
    "            res = model.predict(np.expand_dims(sequence, axis=0), verbose=0)[0]\n",
    "            \n",
    "            current_action = actions[np.argmax(res)]\n",
    "            confidence = np.max(res)\n",
    "            \n",
    "            if (confidence < 0.8):\n",
    "                  current_action = ''\n",
    "      \n",
    "      # CPU analysis\n",
    "      new_frame_time = time.time() \n",
    "\n",
    "      fps = 1/(new_frame_time-prev_frame_time) \n",
    "      prev_frame_time = new_frame_time \n",
    "      fps = str(int(fps)) \n",
    "\n",
    "      ram_usage = psutil.virtual_memory().percent\n",
    "      cpu_usage = psutil.cpu_percent()\n",
    "\n",
    "      # putting the FPS count on the frame \n",
    "      cv2.putText(frame, 'FPS: {}'.format(fps), (1000, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (100, 255, 0), 2) \n",
    "\n",
    "      # Display the RAM usage\n",
    "      cv2.putText(frame, f\"RAM Usage: {ram_usage}%\", (1000, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (100, 255, 0), 2)\n",
    "\n",
    "      # Display CPU usage\n",
    "      cv2.putText(frame, f\"CPU Usage: {cpu_usage}%\", (1000, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (100,255,0), 2)\n",
    "      \n",
    "      cv2.rectangle(frame, (0,0), (360, 40), 0.5, -1)\n",
    "      cv2.putText(frame, 'Exercise ' + current_action, (3,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    \n",
    "\n",
    "      cv2.imshow('Output Video', frame)\n",
    "\n",
    "      if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "            break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
