{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-02 15:02:44.727800: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-02 15:02:45.071373: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-02 15:02:45.071487: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-02 15:02:45.142723: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-02 15:02:45.279533: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-02 15:02:45.280504: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-02 15:02:47.059578: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "from enum import Enum\n",
    "import time\n",
    "import psutil\n",
    "import mediapipe as mp\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "thunder_interpreter = tf.lite.Interpreter(model_path='../models/movenet-lightning.tflite')\n",
    "thunder_interpreter.allocate_tensors()\n",
    "\n",
    "input_details = thunder_interpreter.get_input_details()\n",
    "output_details = thunder_interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1712050370.402376 1029907 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1712050370.412853 1030219 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.0.4-0ubuntu1~22.04.1), renderer: Mesa Intel(R) UHD Graphics 620 (KBL GT2)\n"
     ]
    }
   ],
   "source": [
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "CONFIDENCE_THRESHOLD = 0.2\n",
    "\n",
    "class Keypoint(Enum):\n",
    "    NOSE = 0\n",
    "    RIGHT_EYE = 2\n",
    "    LEFT_EYE = 5\n",
    "    RIGHT_EAR = 7\n",
    "    LEFT_EAR = 8\n",
    "    RIGHT_SHOULDER = 11\n",
    "    LEFT_SHOULDER = 12\n",
    "    RIGHT_ELBOW = 13\n",
    "    LEFT_ELBOW = 14\n",
    "    RIGHT_WRIST = 15\n",
    "    LEFT_WRIST = 16\n",
    "    RIGHT_HIP = 23\n",
    "    LEFT_HIP = 24\n",
    "    RIGHT_KNEE = 25\n",
    "    LEFT_KNEE = 26\n",
    "    RIGHT_ANKLE = 27\n",
    "    LEFT_ANKLE = 28\n",
    "    \n",
    "    def __int__(self):\n",
    "        return self.value\n",
    "    \n",
    "    @classmethod\n",
    "    def all_keypoints(cls):\n",
    "        return {key.name: key.value for key in cls}\n",
    "\n",
    "class Edges(Enum):\n",
    "    NOSE_TO_RIGHT_EYE = (Keypoint.NOSE, Keypoint.RIGHT_EYE, 'm')\n",
    "    NOSE_TO_LEFT_EYE = (Keypoint.NOSE, Keypoint.LEFT_EYE, 'c')\n",
    "    RIGHT_EYE_TO_RIGHT_EAR = (Keypoint.RIGHT_EYE, Keypoint.RIGHT_EAR, 'm')\n",
    "    LEFT_EYE_TO_LEFT_EAR = (Keypoint.LEFT_EYE, Keypoint.LEFT_EAR, 'c')\n",
    "    NOSE_TO_RIGHT_SHOULDER = (Keypoint.NOSE, Keypoint.RIGHT_SHOULDER, 'm')\n",
    "    NOSE_TO_LEFT_SHOULDER = (Keypoint.NOSE, Keypoint.LEFT_SHOULDER, 'c')\n",
    "    RIGHT_SHOULDER_TO_RIGHT_ELBOW = (Keypoint.RIGHT_SHOULDER, Keypoint.RIGHT_ELBOW, 'm')\n",
    "    LEFT_SHOULDER_TO_LEFT_ELBOW = (Keypoint.LEFT_SHOULDER, Keypoint.LEFT_ELBOW, 'c')\n",
    "    RIGHT_ELBOW_TO_RIGHT_WRIST = (Keypoint.RIGHT_ELBOW, Keypoint.RIGHT_WRIST, 'm')\n",
    "    LEFT_ELBOW_TO_LEFT_WRIST = (Keypoint.LEFT_ELBOW, Keypoint.LEFT_WRIST, 'c')\n",
    "    RIGHT_SHOULDER_TO_RIGHT_HIP = (Keypoint.RIGHT_SHOULDER, Keypoint.RIGHT_HIP, 'm')\n",
    "    LEFT_SHOULDER_TO_LEFT_HIP = (Keypoint.LEFT_SHOULDER, Keypoint.LEFT_HIP, 'c')\n",
    "    RIGHT_HIP_TO_RIGHT_KNEE = (Keypoint.RIGHT_HIP, Keypoint.RIGHT_KNEE, 'm')\n",
    "    LEFT_HIP_TO_LEFT_KNEE = (Keypoint.LEFT_HIP, Keypoint.LEFT_KNEE, 'c')\n",
    "    RIGHT_KNEE_TO_RIGHT_ANKLE = (Keypoint.RIGHT_KNEE, Keypoint.RIGHT_ANKLE, 'm')\n",
    "    LEFT_KNEE_TO_LEFT_ANKLE = (Keypoint.LEFT_KNEE, Keypoint.LEFT_ANKLE, 'c')\n",
    "    LEFT_SHOULDER_TO_RIGHT_SHOULDER = (Keypoint.LEFT_SHOULDER,Keypoint.RIGHT_SHOULDER, 'y')\n",
    "    LEFT_HIP_TO_RIGHT_HIP = (Keypoint.LEFT_HIP,Keypoint.RIGHT_HIP, 'y')\n",
    "    \n",
    "    @classmethod\n",
    "    def all_edges(cls):\n",
    "        return [(edge.value[0].value, edge.value[1].value, edge.value[2]) for edge in cls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints(frame, keypoints, confidence_threshold=0):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    for kp in shaped:\n",
    "        ky, kx, kp_conf = kp\n",
    "        if kp_conf > confidence_threshold:\n",
    "            cv2.circle(frame, (int(kx), int(ky)), 4, (0,255,0), -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_connections(frame, keypoints, edges, confidence_threshold=0):\n",
    "    y, x, _ = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    color_mapping = {'m': (255, 0, 255), 'c': (255, 255, 0), 'y': (0, 255, 255)}\n",
    "    \n",
    "    for p1,p2, color in edges:\n",
    "        y1, x1, c1 = shaped[p1]\n",
    "        y2, x2, c2 = shaped[p2]\n",
    "        \n",
    "        if (c1 > confidence_threshold) & (c2 > confidence_threshold):      \n",
    "            cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), color_mapping[color], 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(frame, keypoints, keypoint1, keypoint2, keypoint3, confidence_threshold=0.0):\n",
    "    y, x, _ = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    keypoint1_coordinate = shaped[int(keypoint1)]\n",
    "    keypoint2_coordinate = shaped[int(keypoint2)]\n",
    "    keypoint3_coordinate = shaped[int(keypoint3)]\n",
    "    \n",
    "    if keypoint1_coordinate[2] < confidence_threshold or keypoint2_coordinate[2] < confidence_threshold or keypoint3_coordinate[2] < confidence_threshold:\n",
    "        return None\n",
    "    \n",
    "    # Convert normalized coordinates to pixel coordinates\n",
    "    y_scale, x_scale = 1.0, 1.0 \n",
    "    kp1_x, kp1_y = keypoint1_coordinate[0] * x_scale, keypoint1_coordinate[1] * y_scale\n",
    "    kp2_x, kp2_y = keypoint2_coordinate[0] * x_scale, keypoint2_coordinate[1] * y_scale\n",
    "    kp3_x, kp3_y = keypoint3_coordinate[0] * x_scale, keypoint3_coordinate[1] * y_scale\n",
    "    \n",
    "    # Calculate vectors\n",
    "    vector1 = np.array([kp1_x - kp2_x, kp1_y - kp2_y])\n",
    "    vector2 = np.array([kp3_x - kp2_x, kp3_y - kp2_y])\n",
    "    \n",
    "    # Calculate dot product\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    \n",
    "    # Calculate magnitudes\n",
    "    magnitude1 = np.linalg.norm(vector1)\n",
    "    magnitude2 = np.linalg.norm(vector2)\n",
    "    \n",
    "    # Calculate cosine of the angle\n",
    "    cosine_angle = dot_product / (magnitude1 * magnitude2)\n",
    "    \n",
    "    # Calculate the angle in radians\n",
    "    angle_rad = np.arccos(np.clip(cosine_angle, -1.0, 1.0))\n",
    "    \n",
    "    # Convert angle to degrees\n",
    "    angle_deg = np.degrees(angle_rad)\n",
    "    \n",
    "    return angle_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_reps(exercise_type, frame, keypoints, confidence_threshold=0.0):\n",
    "    y, x, _ = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y, x, 1]))\n",
    "\n",
    "    global rep\n",
    "    global state\n",
    "    \n",
    "    if exercise_type == \"curls\":\n",
    "\n",
    "        angle = calculate_angle(frame, keypoints,  Keypoint.LEFT_SHOULDER,\n",
    "                                Keypoint.LEFT_ELBOW, Keypoint.LEFT_WRIST, confidence_threshold)\n",
    "        \n",
    "        if angle == None:\n",
    "            return\n",
    "        if angle < 30:\n",
    "            state = \"up\"\n",
    "        if angle > 140 and state == 'up':\n",
    "            state = \"down\"\n",
    "            rep += 1\n",
    "        if angle > 140 and state == None:\n",
    "            state = \"down\"\n",
    "\n",
    "        shoulder_keypoint = shaped[int(Keypoint.LEFT_ELBOW)]\n",
    "        kp_x, kp_y = int(shoulder_keypoint[0]), int(shoulder_keypoint[1])\n",
    "\n",
    "        cv2.putText(frame, f'{angle:.2f}', (kp_x, kp_y),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "\n",
    "    elif exercise_type == \"squats\":\n",
    "        \n",
    "        # Calculate knee angles\n",
    "        left_knee_angle = calculate_angle(frame, keypoints,Keypoint.LEFT_HIP, Keypoint.LEFT_KNEE, Keypoint.LEFT_ANKLE)\n",
    "        right_knee_angle = calculate_angle(frame, keypoints,Keypoint.RIGHT_HIP, Keypoint.RIGHT_KNEE, Keypoint.RIGHT_ANKLE)\n",
    "\n",
    "        # Calculate hip angles\n",
    "        left_hip_angle = calculate_angle(frame, keypoints,Keypoint.LEFT_SHOULDER, Keypoint.LEFT_HIP, Keypoint.LEFT_KNEE)\n",
    "        right_hip_angle = calculate_angle(frame, keypoints,Keypoint.RIGHT_SHOULDER, Keypoint.RIGHT_HIP, Keypoint.RIGHT_KNEE)\n",
    "        \n",
    "        if(left_knee_angle == None or right_knee_angle == None or left_hip_angle == None or right_hip_angle == None):\n",
    "            return\n",
    "        \n",
    "        thr = 135\n",
    "        if (left_knee_angle < thr) and (right_knee_angle < thr) and (left_hip_angle < thr) and (right_hip_angle < thr):\n",
    "            state = \"down\"\n",
    "        if (left_knee_angle > thr) and (right_knee_angle > thr) and (left_hip_angle > thr) and (right_hip_angle > thr) and (state == 'down'):\n",
    "            state = 'up'\n",
    "            rep += 1\n",
    "        if (left_knee_angle > thr) and (right_knee_angle > thr) and (left_hip_angle > thr) and (right_hip_angle > thr) and (state == None):\n",
    "            state = 'up'\n",
    "\n",
    "    elif exercise_type == \"press\":\n",
    "        \n",
    "        elbow_angle = calculate_angle(frame, keypoints,  Keypoint.LEFT_SHOULDER,\n",
    "                                Keypoint.LEFT_ELBOW, Keypoint.LEFT_WRIST, confidence_threshold)\n",
    "        \n",
    "        # Compute distances between joints\n",
    "        shoulder2elbow_dist = abs(math.dist(shaped[int(Keypoint.LEFT_SHOULDER)],shaped[int(Keypoint.LEFT_ELBOW)]))\n",
    "        shoulder2wrist_dist = abs(math.dist(shaped[int(Keypoint.LEFT_SHOULDER)],shaped[int(Keypoint.LEFT_WRIST)]))\n",
    "        \n",
    "        if (elbow_angle > 130) and (shoulder2elbow_dist < shoulder2wrist_dist):\n",
    "            state = \"up\"\n",
    "        if (elbow_angle < 50) and (shoulder2elbow_dist > shoulder2wrist_dist) and (state =='up'):\n",
    "            state='down'\n",
    "            rep += 1\n",
    "        if (elbow_angle < 50) and (shoulder2elbow_dist > shoulder2wrist_dist) and (state == None):\n",
    "            state='down'\n",
    "\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture('../dataset/hammer curl/hammer curl_19.mp4')\n",
    "cap = cv2.VideoCapture('../dataset/shoulder press/shoulder press_12.mp4')\n",
    "# cap = cv2.VideoCapture('../dataset/barbell biceps curl/barbell biceps curl_46.mp4')\n",
    "\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "rep = 0\n",
    "state = None\n",
    "\n",
    "prev_frame_time = 0\n",
    "new_frame_time = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret: \n",
    "      break\n",
    "    \n",
    "    # Preprocess frame\n",
    "    img = frame.copy()\n",
    "    img = tf.image.resize_with_pad(np.expand_dims(img, axis=0), 192,192)\n",
    "    input_image = tf.cast(img, dtype=tf.float32)\n",
    "    \n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(rgb_frame)\n",
    "    \n",
    "    if results.pose_landmarks:\n",
    "         mp.solutions.drawing_utils.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "    else: continue\n",
    "    \n",
    "    keypoints_with_scores = [(landmark.x,\n",
    "                              landmark.y,\n",
    "                              landmark.visibility)\n",
    "                             for landmark in results. pose_landmarks.landmark]\n",
    "    \n",
    "    # Make predictions \n",
    "    # thunder_interpreter.set_tensor(input_details[0]['index'], np.array(input_image))\n",
    "    # thunder_interpreter.invoke()\n",
    "    # keypoints_with_scores = thunder_interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "    # CPU analysis\n",
    "    new_frame_time = time.time() \n",
    "    \n",
    "    fps = 1/(new_frame_time-prev_frame_time) \n",
    "    prev_frame_time = new_frame_time \n",
    "    fps = str(int(fps)) \n",
    "    \n",
    "    ram_usage = psutil.virtual_memory().percent\n",
    "    cpu_usage = psutil.cpu_percent()\n",
    "\n",
    "    # putting the FPS count on the frame \n",
    "    cv2.putText(frame, 'FPS: {}'.format(fps), (1000, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (100, 255, 0), 2) \n",
    "    \n",
    "    # Display the RAM usage\n",
    "    cv2.putText(frame, f\"RAM Usage: {ram_usage}%\", (1000, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (100, 255, 0), 2)\n",
    "    \n",
    "    # Display CPU usage\n",
    "    cv2.putText(frame, f\"CPU Usage: {cpu_usage}%\", (1000, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (100,255,0), 2)\n",
    "\n",
    "    \n",
    "    # Rendering     \n",
    "    # draw_connections(frame, keypoints_with_scores, Edges.all_edges(), CONFIDENCE_THRESHOLD)\n",
    "    # draw_keypoints(frame, keypoints_with_scores, CONFIDENCE_THRESHOLD)\n",
    "    \n",
    "    count_reps('press', frame, keypoints_with_scores, CONFIDENCE_THRESHOLD)\n",
    "    \n",
    "    cv2.rectangle(frame, (0,0), (360, 40), 0.5, -1)\n",
    "    cv2.putText(frame, 'reps ' + str(rep), (3,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(frame, ' - state: ' + str(state), (110,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow('Output Video', frame)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
