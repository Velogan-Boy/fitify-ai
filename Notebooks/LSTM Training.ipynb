{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zFuHJMubyUX"
      },
      "outputs": [],
      "source": [
        "!pip install mediapipe\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import math\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n"
      ],
      "metadata": {
        "id": "62K8TdXT0bPe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract landmarks from a video file\n",
        "def extract_landmarks(video_path):\n",
        "    # Use Mediapipe to extract landmarks from each frame of the video\n",
        "    mp_pose = mp.solutions.pose\n",
        "    pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    landmarks = []\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        results = pose.process(rgb_frame)\n",
        "        if results.pose_landmarks:\n",
        "            landmark_list = [lm.x for lm in results.pose_landmarks.landmark]  # Example: Use x-coordinates of landmarks\n",
        "            landmarks.append(landmark_list)\n",
        "    cap.release()\n",
        "    return landmarks\n",
        "\n",
        "# Path to the directory containing the gym exercise videos\n",
        "data_dir = \"Workout_Video\"\n",
        "\n",
        "result_dir = \"Workout_Video_Extracts\"\n",
        "\n",
        "# List of gym exercise classes (subfolders in the data directory)\n",
        "exercise_classes = os.listdir(data_dir)\n",
        "\n",
        "print(\"Preparing Dataset\")\n",
        "# Prepare the dataset\n",
        "for i, exercise_class in enumerate(exercise_classes):\n",
        "    class_dir = os.path.join(data_dir, exercise_class)\n",
        "\n",
        "    output_dir = os.path.join(result_dir, exercise_class)\n",
        "    result_file_path_x = output_dir + \"+X.txt\"\n",
        "    result_file_path_y = output_dir + \"+y.txt\"\n",
        "\n",
        "    filenamey = exercise_class + \"+y.txt\"\n",
        "\n",
        "    if filenamey in os.listdir(result_dir):\n",
        "      continue\n",
        "    print(class_dir)\n",
        "\n",
        "    xin, yin = [], []\n",
        "    for video_file in os.listdir(class_dir):\n",
        "        video_path = os.path.join(class_dir, video_file)\n",
        "        landmarks = extract_landmarks(video_path)\n",
        "        xin.append(landmarks)\n",
        "        yin.append(i)\n",
        "\n",
        "    with open(result_file_path_x, \"wb\") as filex:\n",
        "      pickle.dump(xin, filex)\n",
        "    with open(result_file_path_y, \"wb\") as filey:\n",
        "      pickle.dump(yin, filey)\n"
      ],
      "metadata": {
        "id": "tDl7Fk78zawL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = [], []\n",
        "for exercise_class in exercise_classes:\n",
        "    print(exercise_class)\n",
        "    output_dir = os.path.join(result_dir, exercise_class)\n",
        "    result_file_path_x = output_dir + \"+X.txt\"\n",
        "    result_file_path_y = output_dir + \"+y.txt\"\n",
        "\n",
        "    with open(result_file_path_x, \"rb\") as filex:\n",
        "      for inpx in pickle.load(filex):\n",
        "        X.append(inpx)\n",
        "    with open(result_file_path_y, \"rb\") as filey:\n",
        "      for inpy in pickle.load(filey):\n",
        "        y.append(inpy)\n"
      ],
      "metadata": {
        "id": "MdUgngIezrk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"splitting Dataset\")\n",
        "# Split the dataset into training, validation, and test sets\n",
        "X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)\n",
        "\n",
        "num_landmarks = 33\n",
        "\n",
        "print(\"Padding or truncating dataset\")\n",
        "# Pad or truncate sequences to ensure they have the same length\n",
        "\n",
        "fixed_seq_length = 250\n",
        "\n",
        "\n",
        "X_train = [seq[:len(seq)] + [[0] * num_landmarks] * (fixed_seq_length - len(seq)) if len(seq) < fixed_seq_length else seq[:fixed_seq_length] for seq in X_train]\n",
        "X_val = [seq[:len(seq)] + [[0] * num_landmarks] * (fixed_seq_length - len(seq)) if len(seq) < fixed_seq_length else seq[:fixed_seq_length] for seq in X_val]\n",
        "X_test = [seq[:len(seq)] + [[0] * num_landmarks] * (fixed_seq_length - len(seq)) if len(seq) < fixed_seq_length else seq[:fixed_seq_length] for seq in X_test]\n"
      ],
      "metadata": {
        "id": "IDbqr3yAzsx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to numpy arrays\n",
        "X_train = np.array(X_train)\n",
        "X_val = np.array(X_val)\n",
        "X_test = np.array(X_test)\n",
        "y_train = np.array(y_train)\n",
        "y_val = np.array(y_val)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "BPOw8Q2J0IZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 30\n",
        "num_input_values = 132\n",
        "actions = np.array(['curl', 'press', 'squat'])"
      ],
      "metadata": {
        "id": "WU3X0FK31Gvb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm = Sequential()\n",
        "lstm.add(LSTM(128, return_sequences=True, activation='relu', input_shape=(sequence_length, num_input_values)))\n",
        "lstm.add(LSTM(256, return_sequences=True, activation='relu'))\n",
        "lstm.add(LSTM(128, return_sequences=False, activation='relu'))\n",
        "lstm.add(Dense(128, activation='relu'))\n",
        "lstm.add(Dense(64, activation='relu'))\n",
        "lstm.add(Dense(actions.shape[0], activation='softmax'))\n",
        "print(lstm.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bT2wE-w0NXE",
        "outputId": "35f49535-3102-496a-bb4b-d6f66d9a7ff9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_3 (LSTM)               (None, 30, 128)           133632    \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 30, 256)           394240    \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 128)               197120    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 749955 (2.86 MB)\n",
            "Trainable params: 749955 (2.86 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "lstm.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "id": "eCcBCkDo0x2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = lstm\n",
        "model_name = \"LSTM\"\n",
        "yhat = model.predict(X_test, verbose=0)\n",
        "\n",
        "# Get list of classification predictions\n",
        "ytrue = np.argmax(y_test, axis=1).tolist()\n",
        "yhat = np.argmax(yhat, axis=1).tolist()\n",
        "\n",
        "# Model accuracy\n",
        "classification_accuracy = accuracy_score(ytrue, yhat)\n",
        "print(f\"{model_name} classification accuracy = {round(classification_accuracy*100,3)}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R87E80zH2Qg2",
        "outputId": "2f41ebe1-a1b8-475e-be48-87355f22f4b7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM classification accuracy = 86.667%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "yhat = model.predict(X_test, verbose=0)\n",
        "\n",
        "# Get list of classification predictions\n",
        "ytrue = np.argmax(y_test, axis=1).tolist()\n",
        "yhat = np.argmax(yhat, axis=1).tolist()\n",
        "\n",
        "# Precision, recall, and f1 score\n",
        "report = classification_report(ytrue, yhat, target_names=actions, output_dict=True)\n",
        "\n",
        "precision = report['weighted avg']['precision']\n",
        "recall = report['weighted avg']['recall']\n",
        "f1_score = report['weighted avg']['f1-score']\n",
        "\n",
        "print(f\"{model_name} weighted average precision = {round(precision,3)}\")\n",
        "print(f\"{model_name} weighted average recall = {round(recall,3)}\")\n",
        "print(f\"{model_name} weighted average f1-score = {round(f1_score,3)}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAbtbCnZ2R7p",
        "outputId": "5b820cda-059c-44fd-c312-ff15d7129537"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM weighted average precision = 0.894\n",
            "LSTM weighted average recall = 0.867\n",
            "LSTM weighted average f1-score = 0.868\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EcYoQG4y2cmy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}